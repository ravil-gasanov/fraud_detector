{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9a6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954c7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a033c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select promising features discovered during the EDA\n",
    "X = train[[\"V4\", \"V11\", \"V7\", \"Amount\"]].astype(\"Float64\")\n",
    "\n",
    "# engineer new features\n",
    "X[\"V4xV11\"] = X[\"V4\"] * X[\"V11\"]\n",
    "\n",
    "X[\"V7_is_negative\"] = X[\"V7\"] < 0\n",
    "X[\"V7_is_negative\"] = X[\"V7_is_negative\"].astype(\"Int64\")\n",
    "\n",
    "y = train[\"Class\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da8733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\n",
    "        \"classifier\",\n",
    "        LogisticRegression(random_state=42, max_iter=1000, solver=\"liblinear\")\n",
    "    ),\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff684d16",
   "metadata": {},
   "source": [
    "# What metric to pick?\n",
    "\n",
    "Since the class distribution is highly imbalanced (only 0.17% of the transactions are fraud), we cannot use metrics like *accuracy*.\n",
    "\n",
    "This is easy to see, if you consider a model that always predicts *not fraud* - which would achieve >99% accuracy, but be utterly useless.\n",
    "\n",
    "Furthermore, we can't solely rely on *recall* either - since a high number of false positives (non-frauds classified as frauds) will have a negative impact on the business (e.g. a bank) as well.\n",
    "\n",
    "We will start with the simple (unweighted) F1-score as a more appropriate metric, since it balances *precision* and *recall* evenly, and consider giving more weight to recall in the future, since false negatives (frauds we couldn't catch) are more expensive than false positives (e.g. a delay or a misunderstanding that could be fixed with minimal human intervention in most cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b17699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# although the number of samples is reasonably large, and a random split would likely yield representative folds,\n",
    "# since the dataset is highly imbalanced, and the positive class is rare (0.17% of the samples)\n",
    "# we opt for a stratified k-fold cross-validation to be safe\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3ff22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior\n",
      "[0. 0. 0. 0. 0.]\n",
      "always fraud\n",
      "[0.00341753 0.00346127 0.00346127 0.00346127 0.00346127]\n",
      "always not fraud\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# to gain insight into our metric of choice, we will first evaluate a few dummy models\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# predict fraud with probability: number of frauds / number of samples\n",
    "prior = DummyClassifier(strategy=\"prior\", random_state=42)\n",
    "\n",
    "print(\"prior\")\n",
    "print(cross_val_score(estimator=prior, X=X, y=y, scoring=\"f1\", cv=skf))\n",
    "\n",
    "# always predict fraud\n",
    "always_positive = DummyClassifier(strategy=\"constant\", constant=1, random_state=42)\n",
    "print(\"always fraud\")\n",
    "print(cross_val_score(estimator=always_positive, X=X, y=y, scoring=\"f1\", cv=skf))\n",
    "\n",
    "# always predict not fraud\n",
    "always_negative = DummyClassifier(strategy=\"constant\", constant=0, random_state=42)\n",
    "print(\"always not fraud\")\n",
    "print(cross_val_score(estimator=always_negative, X=X, y=y, scoring=\"f1\", cv=skf)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf48369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58064516, 0.55172414, 0.58267717, 0.60655738, 0.56666667])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now our baseline logistic regression model\n",
    "cross_val_score(estimator=pipeline, X=X, y=y, scoring=\"f1\", cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae42101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/baseline.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)\n",
    "\n",
    "joblib.dump(pipeline, \"../models/baseline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299cfd73",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Key takeaways:\n",
    "1. We deliberated and picked an appropriate metric for the imbalanced fraud dataset - *F1 score*.\n",
    "2. We established a baseline using a simple logistic regression model.\n",
    "3. We sanity checked our metric and baseline by comparing it against a few dummy models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
